{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Who am I? I'm a Python programmer with a background in psychological research, a hobbyist web / graphic designer, a TTRPG enthusiast, and generally an all round tech nerd. PsychoPy PsychoPy is Python library and accompanying graphical interface for building psychology experiments, designed to be accurate enough for publication-quality research but intuitive enough for undergraduate students. I've been using PsychoPy as a student and technician for many years, and since May 2020 I've been working as a Python developer on PsychoPy. I mostly work on the front-end; improving the look and feel of the app, creating new Components and defining the code which Builder writes for them. Read more... Research Anyone familiar with video gaming can attest to the physiological response we experience following certain in-game events: a racing heartbeat as you narrowly avoid an enemy attack or sweaty palms as you make a risky play with for a big payoff. Within gaming communities, the term \" sweaty \" is even used as slang for taking the game too seriously. I'm interested in how our relationship to virtual avatars mediates our physiological reactions to events within a virtual environment; if your avatar takes damage in a video game, do you react differently depending on your relationship to that avatar? Read more... Education MSc Psychological Research Methods The University of Lincoln September 2017 - December 2019 Thesis title: How Do Player-Avatar Relationships Mediate Physiological Responses To In-Game Events? BSc Psychology, First Class Honors The University of Lincoln September 2012 - June 2015 Dissertation title: Relationships between evolutionary threat and spectral slope. Publications Mather, G., & Parsons, T. (2018). Adaptation reveals sensory and decision components in the visual estimation of locomotion speed. Scientific reports, 8 (1), 13059 Mather, G., Sharman, R. J., & Parsons, T. (2017). Visual adaptation alters the apparent speed of real-world actions. Scientific reports, 7 (1), 6738. Employment Python Developer Open Science Tools Ltd. Jan 2021 - Present Once my contract under the University of Nottingham expired, I was taken on by OST on a permanent basis to continue working on PsychoPy, particularly the user interface. Python Programmer for Psychopy The University of Nottingham May 2020 - Jan 2021 I was hired under a CZI grant to help improve the stability of PsychoPy around the 2020.2 and 2021.1 releases. Psychology Technician The University of Lincoln January 2017 - May 2020 As a technician, I assisted staff and students with a variety of technical issues. In particular, scripting in Matlab, creating graphical resources and managing an online research presence. Research Assistant The University of Lincoln April 2016 - December 2016 In 2016 I was employed by Professor George Mather at the University of Lincoln as a research assistant, assisting with the final year of a collaboration between himself and Doctor Rebecca Sharman, looking at early visual processing of human locomotion . Awards Technical Support in Psychology Research Award From: British Psychological Society, July 2020 To: Psychology Technician Team (University of Lincoln) We are so proud of our amazing technicians @PsychTechnician who won the Technical Support in Psychology Award from the BPS! @BPSOfficial Well done, and thank you for all your hard work! buff.ly/3ei5JeA #psychlincs @bydhifu @ManOCheese @ToddEParsons @___charl @PsychLincoln via X Team Achievement Award: Best Achievement In Customer Service From: University of Lincoln, December 2019 To: Psychology Technician Team Congratulations to our #psychlincs #UoLSMA19 winners yesterday! @thisdrkmckenzie (Best Practice), @LMarechal_ & Dr Ava Horowitz (Individual Merit), @kayritchiepsych (Vice Chancellor's), #pint18lincoln (Public Engagement) and @PsychTechnician (Team Achievement)! Phew, what a list! @PsychLincoln via X Professional memberships University and College Union (UCU) Member January 2017 - Present University of Lincoln School of Psychology Equality Committee (SPEC) Technician Representative, LGBTQI+ Champion January 2017 - May 2020 For more information on the School of Psychology Equality Committee, please see the SPEC website . Association of Technical Staff in Psychology (ATSiP) Member January 2017 - May 2020 For more information on the Association of Technical Staff in Psychology, please see the ATSiP website . University of Lincoln Perception, Action & Cognition (PAC) Research Group Member April 2016 - May 2020 For more information on the Perception, Action & Cognition group at Lincoln, please see the PAC group website . Other Projects CSS Themes As you may be able to tell from this website, I enjoy making CSS themes. It gives me an outlet for my inherent aesthetic snobbery, I find it relaxing making minor tweaks to the spacing of such-and-such element to get a page rendering exactly how I want it. Torillic Torillic is designed to look like the official material for Dungeons & Dragons, I use it to write notes for my TTRPG campaigns and to style them once compiled and hosted to wiki-style websites. Read more... LCARS LCARS is designed to look like the fictional LCARS operating system from Star Trek. Like Torillic, I like to use it for TTRPG campaign notes, but in this case the more sci-fi adjacent settings. Whitelines Whitelines is the theme I use most in my day-to-day markdown editing. It's designed to look like Whitelines notepads, which (being a stationery nerd) are my favourite kind of notebook to write on. So it only makes sense to edit markdown on the same kind of paper! Python GUI Working with a Python-based graphical user interface (GUI) at Open Science Tools gives me a thorough familiarity with the GUI packages used in Python, sometimes I find myself wishing for certain widgets to exist so in my free time I go ahead and make them. pygments-gui pygments-gui is a plugin for Pygments , a Python package which takes code and applies syntactic styling to it. The plugin adds classes and methods for using Pygments within a GUI, styling the contents of text controls live in a fast and efficient way. You can find pygments-gui on GitHub here .","title":"Home"},{"location":"#who-am-i","text":"I'm a Python programmer with a background in psychological research, a hobbyist web / graphic designer, a TTRPG enthusiast, and generally an all round tech nerd.","title":"Who am I?"},{"location":"#psychopy","text":"PsychoPy is Python library and accompanying graphical interface for building psychology experiments, designed to be accurate enough for publication-quality research but intuitive enough for undergraduate students. I've been using PsychoPy as a student and technician for many years, and since May 2020 I've been working as a Python developer on PsychoPy. I mostly work on the front-end; improving the look and feel of the app, creating new Components and defining the code which Builder writes for them. Read more...","title":"PsychoPy"},{"location":"#research","text":"Anyone familiar with video gaming can attest to the physiological response we experience following certain in-game events: a racing heartbeat as you narrowly avoid an enemy attack or sweaty palms as you make a risky play with for a big payoff. Within gaming communities, the term \" sweaty \" is even used as slang for taking the game too seriously. I'm interested in how our relationship to virtual avatars mediates our physiological reactions to events within a virtual environment; if your avatar takes damage in a video game, do you react differently depending on your relationship to that avatar? Read more...","title":"Research"},{"location":"#education","text":"","title":"Education"},{"location":"#msc-psychological-research-methods","text":"The University of Lincoln September 2017 - December 2019 Thesis title: How Do Player-Avatar Relationships Mediate Physiological Responses To In-Game Events?","title":"MSc Psychological Research Methods"},{"location":"#bsc-psychology-first-class-honors","text":"The University of Lincoln September 2012 - June 2015 Dissertation title: Relationships between evolutionary threat and spectral slope.","title":"BSc Psychology, First Class Honors"},{"location":"#publications","text":"Mather, G., & Parsons, T. (2018). Adaptation reveals sensory and decision components in the visual estimation of locomotion speed. Scientific reports, 8 (1), 13059 Mather, G., Sharman, R. J., & Parsons, T. (2017). Visual adaptation alters the apparent speed of real-world actions. Scientific reports, 7 (1), 6738.","title":"Publications"},{"location":"#employment","text":"","title":"Employment"},{"location":"#python-developer","text":"Open Science Tools Ltd. Jan 2021 - Present Once my contract under the University of Nottingham expired, I was taken on by OST on a permanent basis to continue working on PsychoPy, particularly the user interface.","title":"Python Developer"},{"location":"#python-programmer-for-psychopy","text":"The University of Nottingham May 2020 - Jan 2021 I was hired under a CZI grant to help improve the stability of PsychoPy around the 2020.2 and 2021.1 releases.","title":"Python Programmer for Psychopy"},{"location":"#psychology-technician","text":"The University of Lincoln January 2017 - May 2020 As a technician, I assisted staff and students with a variety of technical issues. In particular, scripting in Matlab, creating graphical resources and managing an online research presence.","title":"Psychology Technician"},{"location":"#research-assistant","text":"The University of Lincoln April 2016 - December 2016 In 2016 I was employed by Professor George Mather at the University of Lincoln as a research assistant, assisting with the final year of a collaboration between himself and Doctor Rebecca Sharman, looking at early visual processing of human locomotion .","title":"Research Assistant"},{"location":"#awards","text":"","title":"Awards"},{"location":"#technical-support-in-psychology-research-award","text":"From: British Psychological Society, July 2020 To: Psychology Technician Team (University of Lincoln) We are so proud of our amazing technicians @PsychTechnician who won the Technical Support in Psychology Award from the BPS! @BPSOfficial Well done, and thank you for all your hard work! buff.ly/3ei5JeA #psychlincs @bydhifu @ManOCheese @ToddEParsons @___charl @PsychLincoln via X","title":"Technical Support in Psychology Research Award"},{"location":"#team-achievement-award-best-achievement-in-customer-service","text":"From: University of Lincoln, December 2019 To: Psychology Technician Team Congratulations to our #psychlincs #UoLSMA19 winners yesterday! @thisdrkmckenzie (Best Practice), @LMarechal_ & Dr Ava Horowitz (Individual Merit), @kayritchiepsych (Vice Chancellor's), #pint18lincoln (Public Engagement) and @PsychTechnician (Team Achievement)! Phew, what a list! @PsychLincoln via X","title":"Team Achievement Award: Best Achievement In Customer Service"},{"location":"#professional-memberships","text":"","title":"Professional memberships"},{"location":"#university-and-college-union-ucu","text":"Member January 2017 - Present","title":"University and College Union (UCU)"},{"location":"#university-of-lincoln-school-of-psychology-equality-committee-spec","text":"Technician Representative, LGBTQI+ Champion January 2017 - May 2020 For more information on the School of Psychology Equality Committee, please see the SPEC website .","title":"University of Lincoln School of Psychology Equality Committee (SPEC)"},{"location":"#association-of-technical-staff-in-psychology-atsip","text":"Member January 2017 - May 2020 For more information on the Association of Technical Staff in Psychology, please see the ATSiP website .","title":"Association of Technical Staff in Psychology (ATSiP)"},{"location":"#university-of-lincoln-perception-action-cognition-pac-research-group","text":"Member April 2016 - May 2020 For more information on the Perception, Action & Cognition group at Lincoln, please see the PAC group website .","title":"University of Lincoln Perception, Action &amp; Cognition (PAC) Research Group"},{"location":"#other-projects","text":"","title":"Other Projects"},{"location":"#css-themes","text":"As you may be able to tell from this website, I enjoy making CSS themes. It gives me an outlet for my inherent aesthetic snobbery, I find it relaxing making minor tweaks to the spacing of such-and-such element to get a page rendering exactly how I want it.","title":"CSS Themes"},{"location":"#torillic","text":"Torillic is designed to look like the official material for Dungeons & Dragons, I use it to write notes for my TTRPG campaigns and to style them once compiled and hosted to wiki-style websites. Read more...","title":"Torillic"},{"location":"#lcars","text":"LCARS is designed to look like the fictional LCARS operating system from Star Trek. Like Torillic, I like to use it for TTRPG campaign notes, but in this case the more sci-fi adjacent settings.","title":"LCARS"},{"location":"#whitelines","text":"Whitelines is the theme I use most in my day-to-day markdown editing. It's designed to look like Whitelines notepads, which (being a stationery nerd) are my favourite kind of notebook to write on. So it only makes sense to edit markdown on the same kind of paper!","title":"Whitelines"},{"location":"#python-gui","text":"Working with a Python-based graphical user interface (GUI) at Open Science Tools gives me a thorough familiarity with the GUI packages used in Python, sometimes I find myself wishing for certain widgets to exist so in my free time I go ahead and make them.","title":"Python GUI"},{"location":"#pygments-gui","text":"pygments-gui is a plugin for Pygments , a Python package which takes code and applies syntactic styling to it. The plugin adds classes and methods for using Pygments within a GUI, styling the contents of text controls live in a fast and efficient way. You can find pygments-gui on GitHub here .","title":"pygments-gui"},{"location":"articles/psychopy/","text":"Below are some of the major projects I've worked on with PsychoPy, arranged by the version they were released in. Graphical overhaul 2020.2 One of the first things I did with PsychoPy was a revamp of the user interface. Historically, PsychoPy was developed by volunteers in their free time, so generally took a \"function over form\" approach out of necessity. Once I was working full-time on PsychoPy I decided to spend some time modernising the look and feel, replacing the default wxPython elements with custom, cleaner designs and replacing the old icons with bespoke vectors. Below are some before-and-after screenshots of the new look: Before After Now I've since tried to keep a consistent visual theme with PsychoPy, so this is what the app looks like in 2024: Parameter controls 2021.1 In 2021 I revamped the way that individual parameters in PsychoPy Components are represented, expanding on the standard controls (text, checkboxes, drop down menus) to add controls for files, Excel tables, colour values, multi-line code and others. With this I also worked on improving how these values were interpreted by Builder and written into code, and made template Excel files for parameters which people often struggled to format. This was driven by confusion I'd noticed when supporting students using PsychoPy, who often struggled with what values to put into parameters; do file paths need to be relative? Should colours be in RGB? What does the dollar sign mean? Eyetracking 2021.2 Later in 2021 I worked on adding device-agnostic eyetracking support to PsychoPy, through an existing toolkit called ioHub. ioHub had been supported for some time, but wasn't really visible from the Builder interface. I worked with the author of this package to develop simple Components for adding common eyetracking tasks (starting/stopping the device, calibrating and validating, querying whether participants were looking at a region of interest), which worked the same regardless of what specific device you were using. Pavlovia interface 2022.1 In 2022 I worked on improving how the local PsychoPy app interacted with the Pavlovia servers, making it easier for users to browse and find studies online, and to sync their own experiments to Pavlovia to both run online and share with collaborators. Camera support 2022.2 In the latter part of 2022 we added webcam support - my role in this was to add the Component to Builder and create code for both Python and JavaScript. This meant coordinating across two teams and figuring out, with the needs of both languages, how to make a single unified interface with common parameters to work on both backends. Plugins 2023.1 Plugins were a real paradigm shift for PsychoPy. Previously, in order to support a feature, it had to be added to PsychoPy itself, meaning everyone would get it (and the required packages with it). As PsychoPy got bigger and more capable, this was leading to a problematically large install, so we decided to make PsychoPy pluggable. My role here was to create an interface in the PsychoPy app to pull down a list of known plugins and interact with the backend to install and uninstall them cleanly. I've also since worked a lot on coordinating the various plugin contributors, creating a plugin template repo and have even added a plugin for making dummy responses when piloting myself. Routine settings 2023.2 Traditionally, PsychoPy Routines have been essentially just a list of Component objects. In the latter part of 2023 however I introduced the concept of Routine Settings, allowing users to control parameters of the Routine itself. This meant entire Routines could be disabled for testing, and the whole Routine could have a maximum time (rather than having to infer it from the longest Component). Builder search 2023.2 As it always goes with programming, the things users really click with aren't the things you spent the most time on. Sometimes a small feature you whip up in a day or two ends up being a game changer; the search box for Builder was one such feature. It's incredibly simple - you just press CTRL/CMD + F and a dialog will appear. Type into that dialog and it will show you where your search term features in Components in your experiment. Nothing programatically difficult, but the impact has been huge! Users with dozens of Routines were previously having to manually sift through them all to find one syntax error or undefined variable in a Code Component, now they can jump right to it by just searching the error text. Pilot mode 2024.1 There are a number of researcher behaviours which are generally good practice, but aren't handled by PsychoPy itself. For example, when building an experiment, it's a good idea to run it in windowed mode so you're not stuck behind a full screen experiment if you hit an error. It's also a good idea to have a verbose logging level when building, but you may not want that many messages when running properly. In 2024 I added a \"pilot mode\" to PsychoPy, a running mode which tells PsychoPy that the user isn't currently testing and is just trying their experiment out. PsychoPy then knows to do this \"good behaviour\" - forcing the window out of full screen, increasing logging verbosity, etc. To make sure users don't accidentally gather data in pilot mode, I also added a big obnoxious orange outline, for safety. Hard to miss, right?","title":"PsychoPy"},{"location":"articles/psychopy/#graphical-overhaul","text":"2020.2 One of the first things I did with PsychoPy was a revamp of the user interface. Historically, PsychoPy was developed by volunteers in their free time, so generally took a \"function over form\" approach out of necessity. Once I was working full-time on PsychoPy I decided to spend some time modernising the look and feel, replacing the default wxPython elements with custom, cleaner designs and replacing the old icons with bespoke vectors. Below are some before-and-after screenshots of the new look:","title":"Graphical overhaul"},{"location":"articles/psychopy/#before","text":"","title":"Before"},{"location":"articles/psychopy/#after","text":"","title":"After"},{"location":"articles/psychopy/#now","text":"I've since tried to keep a consistent visual theme with PsychoPy, so this is what the app looks like in 2024:","title":"Now"},{"location":"articles/psychopy/#parameter-controls","text":"2021.1 In 2021 I revamped the way that individual parameters in PsychoPy Components are represented, expanding on the standard controls (text, checkboxes, drop down menus) to add controls for files, Excel tables, colour values, multi-line code and others. With this I also worked on improving how these values were interpreted by Builder and written into code, and made template Excel files for parameters which people often struggled to format. This was driven by confusion I'd noticed when supporting students using PsychoPy, who often struggled with what values to put into parameters; do file paths need to be relative? Should colours be in RGB? What does the dollar sign mean?","title":"Parameter controls"},{"location":"articles/psychopy/#eyetracking","text":"2021.2 Later in 2021 I worked on adding device-agnostic eyetracking support to PsychoPy, through an existing toolkit called ioHub. ioHub had been supported for some time, but wasn't really visible from the Builder interface. I worked with the author of this package to develop simple Components for adding common eyetracking tasks (starting/stopping the device, calibrating and validating, querying whether participants were looking at a region of interest), which worked the same regardless of what specific device you were using.","title":"Eyetracking"},{"location":"articles/psychopy/#pavlovia-interface","text":"2022.1 In 2022 I worked on improving how the local PsychoPy app interacted with the Pavlovia servers, making it easier for users to browse and find studies online, and to sync their own experiments to Pavlovia to both run online and share with collaborators.","title":"Pavlovia interface"},{"location":"articles/psychopy/#camera-support","text":"2022.2 In the latter part of 2022 we added webcam support - my role in this was to add the Component to Builder and create code for both Python and JavaScript. This meant coordinating across two teams and figuring out, with the needs of both languages, how to make a single unified interface with common parameters to work on both backends.","title":"Camera support"},{"location":"articles/psychopy/#plugins","text":"2023.1 Plugins were a real paradigm shift for PsychoPy. Previously, in order to support a feature, it had to be added to PsychoPy itself, meaning everyone would get it (and the required packages with it). As PsychoPy got bigger and more capable, this was leading to a problematically large install, so we decided to make PsychoPy pluggable. My role here was to create an interface in the PsychoPy app to pull down a list of known plugins and interact with the backend to install and uninstall them cleanly. I've also since worked a lot on coordinating the various plugin contributors, creating a plugin template repo and have even added a plugin for making dummy responses when piloting myself.","title":"Plugins"},{"location":"articles/psychopy/#routine-settings","text":"2023.2 Traditionally, PsychoPy Routines have been essentially just a list of Component objects. In the latter part of 2023 however I introduced the concept of Routine Settings, allowing users to control parameters of the Routine itself. This meant entire Routines could be disabled for testing, and the whole Routine could have a maximum time (rather than having to infer it from the longest Component).","title":"Routine settings"},{"location":"articles/psychopy/#builder-search","text":"2023.2 As it always goes with programming, the things users really click with aren't the things you spent the most time on. Sometimes a small feature you whip up in a day or two ends up being a game changer; the search box for Builder was one such feature. It's incredibly simple - you just press CTRL/CMD + F and a dialog will appear. Type into that dialog and it will show you where your search term features in Components in your experiment. Nothing programatically difficult, but the impact has been huge! Users with dozens of Routines were previously having to manually sift through them all to find one syntax error or undefined variable in a Code Component, now they can jump right to it by just searching the error text.","title":"Builder search"},{"location":"articles/psychopy/#pilot-mode","text":"2024.1 There are a number of researcher behaviours which are generally good practice, but aren't handled by PsychoPy itself. For example, when building an experiment, it's a good idea to run it in windowed mode so you're not stuck behind a full screen experiment if you hit an error. It's also a good idea to have a verbose logging level when building, but you may not want that many messages when running properly. In 2024 I added a \"pilot mode\" to PsychoPy, a running mode which tells PsychoPy that the user isn't currently testing and is just trying their experiment out. PsychoPy then knows to do this \"good behaviour\" - forcing the window out of full screen, increasing logging verbosity, etc. To make sure users don't accidentally gather data in pilot mode, I also added a big obnoxious orange outline, for safety. Hard to miss, right?","title":"Pilot mode"},{"location":"articles/research/","text":"How Do Player-Avatar Relationships Mediate Physiological Responses To In-Game Events? When looking at players' physiological responses to watching an avatar being beaten up in Wii BoxingTM, Ratan & Dawson (2016) found that they responded more when they felt emotionally connected to the avatar. So this physiological response to in-game events is affected in some way by our relationship to the avatar we are playing as. Downs, Bowman & Banks (2017) describe what they call a \"Polythetic Model of Player Identification\", in simple terms this means several different aspects of player-avatar relationships interacting to produce an overall experience of connectedness between player and avatar. They split player-avatar identification into six categories: Physical Similarity : How much does the avatar physically resemble you? Value Homophily : How close are the avatar's views, background and outlook on life to your own? Value Homophily : How close are the avatar's views, background and outlook on life to your own? Wishful Identification : Do you wish you were more like the avatar? Liking : Do you like the avatar? Perspective-Taking : Can you take the avatar's perspective, sympathising with its experiences and motives? Embodiment : Does it feel as if you are acting through the avatar, rather than merely controlling it? My MSc thesis research asked the following question: Which of elements of player identification are responsible for Ratan & Dawson's (2016) effect? I investigated this using the game Unreal Tournament 2004 TM; an action-packed first-person shooter in which players compete for \"kills\" and seek to avoid \"deaths\". My fellow technicians Foivos Vantzos, Ferenc Igali and I wrote a mutator for the game; a piece of code which modifies how the game works. This mutator forces the game output two pieces of data every 0.2 seconds for the duration of gameplay: The player's current health and their number of kills. Using this data I was able to identify timestamps of when players took significant (>20%) damage and when they killed an enemy. Cross-correlating this with GSR data taken whilst playing gave a measure of how responsive players were to in-game events, both positive (kills) and negative (damage). I also asked participants to answer the same questions used by Downs, Bowman & Banks (2017) to determine in what way they relate to their chosen avatar. By comparing the two sets of data, responsiveness to in-game events and polythetic factors of player identification, I hope to clarify what specifically it is about human-avatar connections which affect our physiological responses to in-game events.","title":"Research"},{"location":"articles/torillic/","text":"Torillic came out of me wanting to use markdown to write notes for my TTRPG campaigns; I'd found the markdown editor Typora and loved that it lets you write your own custom themes in CSS, so I set about making something which looks like the official resources for Dungeons & Dragons. You can view/download the Typora theme here , below are some previews of how it looks in Typora:","title":"Torillic"}]}